Metadata-Version: 2.1
Name: head-controller
Version: 1.1.0
Summary: A package to quickly train and predict head gestures
Home-page: https://github.com/nightvision04/simple-gesture-tracking
Author: Dan Scott
Author-email: danscottlearns@gmail.com
License: UNKNOWN
Description: 
        
        #### Requirements
        
        - Anaconda Python >= 3.7
        
        #### Quickstart
        
        Quickly train 4 gestures for the model to learn. Press the UP, DOWN, RIGHT, and LEFT arrows on your keyboard to 'label' each gesture in realtime. After 30 seconds you'll be prompted to save (append) the new training data. It will immediately show you a cross-validation score of the fitted data.
        Initialize, Train, and Predict in less than 60 seconds (using your webcam).
        
        
        ```
        import head_controller.db as db
        import head_controller.Camera as Camera
        
        # Initialize gesture training data
        db.setup_db()
        
        # Capture webcam gestures with live arrow-key labelling
        Camera.capture_review_submit_labels()
        
        # Realtime predict webcam gestures
        Camera.check_video_frame_data_predict()
        ```
        
        
Keywords: head,controller,nueral net,movement,axis,recognition,computer vision,head tracking
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Build Tools
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.7
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
