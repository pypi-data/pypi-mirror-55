Metadata-Version: 2.1
Name: newsman
Version: 1.1.0
Summary: A tool for web news scraping.
Home-page: https://github.com/acapitanelli/newsman
Author: Andrea Capitanelli
Author-email: andrea.capitanelli@gmail.com
Maintainer: Andrea Capitanelli
Maintainer-email: andrea.capitanelli@gmail.com
License: MIT
Keywords: press articles text extraction
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Office/Business :: News/Diary
Requires-Python: >=3.6.0
Description-Content-Type: text/markdown
Requires-Dist: chardet
Requires-Dist: requests


# Newsman

A tool for scraping news from web.

There is no AI here, just good old-fashioned if-else rules.

# Usage

Basic usage:

```
import newsman

# start reading
src = 'https://www.bbc.com'
news = newsman.read(src)

# show articles
for article in news:
    print(f'Url: {article.url.url}')
    print(f'Title: {article.title}')
    print(f'Text: {article.text}')
    print(f'Main image: {article.main_image}')
```

Customizing configuration:

```
import newsman

# get configuration
config = newsman.get_config()

# add a proxy for connection
config['proxies'] = proxies

# update accepted/rejected domains
config['accepted_domains'] = ['a-good-site.com', 'the-best-one.org']
config['rejected_domains'] += ['bad.com', 'very.bad.biz']

# override default values for web retrieval
config['link_depth'] = 2            # crawling depth level
config['scan_limit'] = 10           # max. number of scanned sites

# set pipes
pipes = ['byte2html', 'html2text', 'text2title', 'html2image']
news = newsman.News(config, pipes)

src = 'https://www.bbc.com'
pages = news(src)
```

Proxy information is formatted according to [Requests format](https://requests.kennethreitz.org/en/master/user/advanced/#proxies).

# Installation

` pip install newsman `


