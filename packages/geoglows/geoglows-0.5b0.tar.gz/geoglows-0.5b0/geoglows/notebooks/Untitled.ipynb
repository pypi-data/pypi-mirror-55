{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas\n",
    "    import requests\n",
    "    import json\n",
    "    import datetime\n",
    "    import jinja2\n",
    "    import os\n",
    "    import multiprocessing\n",
    "    from plotly.offline import plot as offline_plot\n",
    "    from plotly.graph_objs import Scatter, Layout, Figure\n",
    "    import plotly.graph_objs as go\n",
    "    from io import StringIO\n",
    "    from collections import OrderedDict, namedtuple\n",
    "    import math\n",
    "    from shapely.geometry import Point, MultiPoint, box\n",
    "    from shapely.ops import nearest_points\n",
    "except ImportError as error:\n",
    "    raise error\n",
    "\n",
    "AI4E_ENDPOINT = 'http://aiforearth.azure-api.net/streamflow/'\n",
    "GSPAPI_ENDPOINT = 'http://global-streamflow-prediction.eastus.azurecontainer.io/api/'\n",
    "BYU_ENDPOINT = 'https://tethys2.byu.edu/localsptapi/api/'\n",
    "\n",
    "\n",
    "# FUNCTIONS THAT CALL THE GLOBAL STREAMFLOW PREDICTION API\n",
    "def forecast_stats(reach_id=None, lat=None, lon=None, api_source=BYU_ENDPOINT, api_key=None, return_format='csv'):\n",
    "    # check that a reach_id or a lat&lon were provided\n",
    "    if not reach_id:\n",
    "        if lat and lon:\n",
    "            reach_id = reach_from_latlon(lat, lon)['reach_id']\n",
    "        else:\n",
    "            raise Exception('provide a reach_id or both a lat and lon value')\n",
    "    params = {'reach_id': reach_id, 'return_format': return_format}\n",
    "    # build and execute a request to the api with the user's parameters\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    data = requests.get(api_source + 'ForecastStats/', headers=headers, params=params).text\n",
    "\n",
    "    if return_format == 'csv':\n",
    "        return pandas.read_csv(StringIO(data))\n",
    "    elif return_format == 'json':\n",
    "        return json.loads(data)\n",
    "    elif return_format == 'waterml':\n",
    "        return data\n",
    "\n",
    "\n",
    "def forecast_ensembles(reach_id=None, lat=None, lon=None, api_source=BYU_ENDPOINT, api_key=None, return_format='csv'):\n",
    "    # check that a reach_id or a lat&lon were provided\n",
    "    if not reach_id:\n",
    "        if lat and lon:\n",
    "            reach_id = reach_from_latlon(lat, lon)['reach_id']\n",
    "        else:\n",
    "            raise Exception('provide a reach_id or both a lat and lon value')\n",
    "    params = {'reach_id': reach_id, 'return_format': return_format}\n",
    "    # build and execute a request to the api with the user's parameters\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    data = requests.get(api_source + 'ForecastEnsembles/', headers=headers, params=params).text\n",
    "\n",
    "    if return_format == 'csv':\n",
    "        tmp = pandas.read_csv(StringIO(data), index_col='datetime')\n",
    "        tmp.index = pandas.to_datetime(tmp.index)\n",
    "        return tmp\n",
    "    elif return_format == 'json':\n",
    "        return json.loads(data)\n",
    "    elif return_format == 'waterml':\n",
    "        return data\n",
    "\n",
    "\n",
    "def historic_simulation(reach_id=None, lat=None, lon=None, api_source=BYU_ENDPOINT, api_key=None, return_format='csv'):\n",
    "    # check that a reach_id or a lat&lon were provided\n",
    "    if not reach_id:\n",
    "        if lat and lon:\n",
    "            reach_id = reach_from_latlon(lat, lon)['reach_id']\n",
    "        else:\n",
    "            raise Exception('provide a reach_id or both a lat and lon value')\n",
    "    params = {'reach_id': reach_id, 'return_format': return_format}\n",
    "    # build and execute a request to the api with the user's parameters\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    data = requests.get(api_source + 'HistoricSimulation/', headers=headers, params=params).text\n",
    "\n",
    "    if return_format == 'csv':\n",
    "        return pandas.read_csv(StringIO(data))\n",
    "    elif return_format == 'json':\n",
    "        return json.loads(data)\n",
    "    elif return_format == 'waterml':\n",
    "        return data\n",
    "\n",
    "\n",
    "def seasonal_average(reach_id=None, lat=None, lon=None, api_source=BYU_ENDPOINT, api_key=None, return_format='csv'):\n",
    "    # check that a reach_id or a lat&lon were provided\n",
    "    if not reach_id:\n",
    "        if lat and lon:\n",
    "            reach_id = reach_from_latlon(lat, lon)['reach_id']\n",
    "        else:\n",
    "            raise Exception('provide a reach_id or both a lat and lon value')\n",
    "    params = {'reach_id': reach_id, 'return_format': return_format}\n",
    "    # build and execute a request to the api with the user's parameters\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    data = requests.get(api_source + 'SeasonalAverage/', headers=headers, params=params).text\n",
    "\n",
    "    if return_format == 'csv':\n",
    "        return pandas.read_csv(StringIO(data))\n",
    "    elif return_format == 'json':\n",
    "        return json.loads(data)\n",
    "    elif return_format == 'waterml':\n",
    "        return data\n",
    "\n",
    "\n",
    "def return_periods(reach_id=None, lat=None, lon=None, api_source=BYU_ENDPOINT, api_key=None, return_format='csv'):\n",
    "    # check that a reach_id or a lat&lon were provided\n",
    "    if not reach_id:\n",
    "        if lat and lon:\n",
    "            reach_id = reach_from_latlon(lat, lon)['reach_id']\n",
    "        else:\n",
    "            raise Exception('provide a reach_id or both a lat and lon value')\n",
    "    params = {'reach_id': reach_id, 'return_format': return_format}\n",
    "    # build and execute a request to the api with the user's parameters\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    data = requests.get(api_source + 'ReturnPeriods/', headers=headers, params=params).text\n",
    "\n",
    "    if return_format == 'csv':\n",
    "        return pandas.read_csv(StringIO(data), index_col='return period')\n",
    "    elif return_format == 'json':\n",
    "        return json.loads(data)\n",
    "    elif return_format == 'waterml':\n",
    "        return data\n",
    "\n",
    "\n",
    "def available_dates(reach_id=None, region=None, api_source=BYU_ENDPOINT, api_key=None):\n",
    "    # you need a region for the api call, so the user needs to provide one or a valid reach_id to get it from\n",
    "    if region:\n",
    "        params = {'region': region}\n",
    "    elif reach_id:\n",
    "        params = {'region': reach_to_region(reach_id)}\n",
    "    else:\n",
    "        raise RuntimeError('specify a region or a reach_id')\n",
    "\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    return json.loads(requests.get(api_source + 'AvailableDates/', headers=headers, params=params).text)\n",
    "\n",
    "\n",
    "def available_regions(api_source=BYU_ENDPOINT, api_key=None):\n",
    "    headers = {'Ocp-Apim-Subscription-Key': api_key}\n",
    "    return json.loads(requests.get(api_source + 'AvailableRegions/', headers=headers).text)\n",
    "\n",
    "\n",
    "# FUNCTIONS THAT PROCESS THE RESULTS OF THE API INTO A PLOTLY PLOT OR DICTIONARY\n",
    "def forecast_plot(stats, rperiods, reach_id, outformat='plotly'):\n",
    "    if not isinstance(stats, pandas.DataFrame):\n",
    "        raise ValueError('Sorry, I only process pandas dataframes right now')\n",
    "    if outformat not in ['json', 'plotly', 'plotly_html']:\n",
    "        raise ValueError('invalid outformat specified. pick json or html')\n",
    "\n",
    "    dates = stats['datetime'].tolist()\n",
    "    startdate = dates[0]\n",
    "    enddate = dates[-1]\n",
    "\n",
    "    plot_data = {\n",
    "        'reach_id': reach_id,\n",
    "        'x_ensembles': stats[['datetime', 'mean (m3/s)']].dropna(axis=0)['datetime'].tolist(),\n",
    "        'x_hires':  stats[['datetime', 'high_res (m3/s)']].dropna(axis=0)['datetime'].tolist(),\n",
    "        'y_max': max(stats['max (m3/s)']),\n",
    "        'min': list(stats['min (m3/s)'].dropna(axis=0)),\n",
    "        'mean': list(stats['mean (m3/s)'].dropna(axis=0)),\n",
    "        'max': list(stats['max (m3/s)'].dropna(axis=0)),\n",
    "        'stdlow': list(stats['std_dev_range_lower (m3/s)'].dropna(axis=0)),\n",
    "        'stdup': list(stats['std_dev_range_upper (m3/s)'].dropna(axis=0)),\n",
    "        'hires': list(stats['high_res (m3/s)'].dropna(axis=0)),\n",
    "        'r2': rperiods.iloc[3][0],\n",
    "        'r10': rperiods.iloc[2][0],\n",
    "        'r20': rperiods.iloc[1][0],\n",
    "    }\n",
    "\n",
    "    if outformat == 'json':\n",
    "        return plot_data\n",
    "\n",
    "    meanplot = Scatter(\n",
    "        name='Mean',\n",
    "        x=plot_data['x_ensembles'],\n",
    "        y=plot_data['mean'],\n",
    "        line=dict(color='blue'),\n",
    "    )\n",
    "    maxplot = Scatter(\n",
    "        name='Max',\n",
    "        x=plot_data['x_ensembles'],\n",
    "        y=plot_data['max'],\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(152, 251, 152)', width=0)\n",
    "    )\n",
    "    minplot = Scatter(\n",
    "        name='Min',\n",
    "        x=plot_data['x_ensembles'],\n",
    "        y=plot_data['min'],\n",
    "        fill=None,\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(152, 251, 152)')\n",
    "    )\n",
    "    stdlowplot = Scatter(\n",
    "        name='Std. Dev. Lower',\n",
    "        x=plot_data['x_ensembles'],\n",
    "        y=plot_data['stdlow'],\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line=dict(color='rgb(152, 251, 152)', width=0)\n",
    "    )\n",
    "    stdupplot = Scatter(\n",
    "        name='Std. Dev. Upper',\n",
    "        x=plot_data['x_ensembles'],\n",
    "        y=plot_data['stdup'],\n",
    "        fill='tonexty',\n",
    "        mode='lines',\n",
    "        line={'width': 0, 'color': 'rgb(34, 139, 34)'}\n",
    "    )\n",
    "    hires = Scatter(\n",
    "        name='Higher Resolution',\n",
    "        x=plot_data['x_hires'],\n",
    "        y=plot_data['hires'],\n",
    "        line={'color': 'black'}\n",
    "    )\n",
    "    layout = Layout(\n",
    "        title='Forecasted Streamflow<br>Stream ID: ' + str(reach_id),\n",
    "        xaxis={'title': 'Date'},\n",
    "        yaxis={\n",
    "            'title': 'Streamflow (m<sup>3</sup>/s)',\n",
    "            'range': [0, 1.2 * plot_data['y_max']]\n",
    "        },\n",
    "        shapes=[\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r2'],\n",
    "                y1=plot_data['r10'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='yellow'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r10'],\n",
    "                y1=plot_data['r20'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='red'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r20'],\n",
    "                y1=1.2 * plot_data['y_max'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='purple'\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    figure = Figure([minplot, stdlowplot, stdupplot, maxplot, meanplot, hires], layout=layout)\n",
    "    if outformat == 'plotly':\n",
    "        return figure\n",
    "    if outformat == 'plotly_html':\n",
    "        return offline_plot(\n",
    "            figure,\n",
    "            config={'autosizable': True, 'responsive': True},\n",
    "            output_type='div',\n",
    "            include_plotlyjs=False\n",
    "        )\n",
    "    return\n",
    "\n",
    "\n",
    "def ensembles_plot(ensembles, rperiods, reach_id, outformat='plotly'):\n",
    "    # be sure they gave you the kind of information you need\n",
    "    if not isinstance(ensembles, pandas.DataFrame):\n",
    "        raise ValueError('Sorry, I only process pandas dataframes right now')\n",
    "    if outformat not in ['json', 'plotly', 'plotly_html']:\n",
    "        raise ValueError('invalid outformat specified. pick json or html')\n",
    "\n",
    "    # variables to determine the maximum flow and hold all the scatter plot lines\n",
    "    max_flows = []\n",
    "    scatters = []\n",
    "\n",
    "    # determine the threshold values for return periods and the start/end dates so we can plot them\n",
    "    dates = ensembles.index.tolist()\n",
    "    startdate = dates[0]\n",
    "    enddate = dates[-1]\n",
    "\n",
    "    # process the series' components and store them in a dictionary\n",
    "    plot_data = {\n",
    "        'reach_id': reach_id,\n",
    "        'x_1-51': ensembles['ensemble_01 (m3/s)'].dropna(axis=0).index.tolist(),\n",
    "        'x_52': ensembles['ensemble_52 (m3/s)'].dropna(axis=0).index.tolist(),\n",
    "        'r2': rperiods.iloc[3][0],\n",
    "        'r10': rperiods.iloc[2][0],\n",
    "        'r20': rperiods.iloc[1][0],\n",
    "    }\n",
    "\n",
    "    # add a dictionary entry for each of the ensemble members. the key for each series is the integer ensemble number\n",
    "    for ensemble in ensembles.columns:\n",
    "        plot_data[int(ensemble[9:11])] = ensembles[ensemble].dropna(axis=0).tolist()\n",
    "        max_flows.append(max(plot_data[int(ensemble[9:11])]))\n",
    "    plot_data['y_max'] = max(max_flows)\n",
    "\n",
    "    if outformat == 'json':\n",
    "        return plot_data\n",
    "\n",
    "    # create the high resolution line (ensemble 52)\n",
    "    scatters.append(Scatter(\n",
    "        name='High Resolution',\n",
    "        x=plot_data['x_52'],\n",
    "        y=plot_data[52],\n",
    "        line=dict(color='black')\n",
    "    ))\n",
    "    # create a line for the rest of the ensembles (1-51)\n",
    "    for i in range(1, 52):\n",
    "        scatters.append(Scatter(\n",
    "            name='Ensemble ' + str(i),\n",
    "            x=plot_data['x_1-51'],\n",
    "            y=plot_data[i],\n",
    "        ))\n",
    "\n",
    "    # define a layout for the plot\n",
    "    layout = Layout(\n",
    "        title='Ensemble Predicted Streamflow<br>Stream ID: ' + str(reach_id),\n",
    "        xaxis={'title': 'Date'},\n",
    "        yaxis={\n",
    "            'title': 'Streamflow (m<sup>3</sup>/s)',\n",
    "            'range': [0, 1.2 * plot_data['y_max']]\n",
    "        },\n",
    "        shapes=[\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r2'],\n",
    "                y1=plot_data['r10'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='yellow'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r10'],\n",
    "                y1=plot_data['r20'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='red'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r20'],\n",
    "                y1=1.2 * plot_data['y_max'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='purple'\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    figure = Figure(scatters, layout=layout)\n",
    "    if outformat == 'plotly':\n",
    "        return figure\n",
    "    if outformat == 'plotly_html':\n",
    "        return offline_plot(\n",
    "            figure,\n",
    "            config={'autosizable': True, 'responsive': True},\n",
    "            output_type='div',\n",
    "            include_plotlyjs=False\n",
    "        )\n",
    "    return\n",
    "\n",
    "\n",
    "def historical_plot(hist, rperiods, reach_id, outformat='plotly'):\n",
    "    if not isinstance(hist, pandas.DataFrame):\n",
    "        raise ValueError('Sorry, I only process pandas dataframes right now')\n",
    "    if outformat not in ['json', 'plotly', 'plotly_html']:\n",
    "        raise ValueError('invalid outformat specified. pick json or plotly or plotly_html')\n",
    "\n",
    "    dates = hist['datetime'].tolist()\n",
    "    startdate = dates[0]\n",
    "    enddate = dates[-1]\n",
    "\n",
    "    plot_data = {\n",
    "        'reach_id': reach_id,\n",
    "        'x_datetime': dates,\n",
    "        'y_flow': hist['streamflow (m3/s)'].tolist(),\n",
    "        'y_max': max(hist['streamflow (m3/s)']),\n",
    "        'r2': rperiods.iloc[3][0],\n",
    "        'r10': rperiods.iloc[2][0],\n",
    "        'r20': rperiods.iloc[1][0],\n",
    "    }\n",
    "\n",
    "    if outformat == 'json':\n",
    "        return plot_data\n",
    "\n",
    "    layout = Layout(\n",
    "        title='Historic Streamflow Simulation<br>Stream ID: ' + str(reach_id),\n",
    "        xaxis={\n",
    "            'title': 'Date',\n",
    "            'hoverformat': '%b %d %Y',\n",
    "            'tickformat': '%Y'\n",
    "        },\n",
    "        yaxis={\n",
    "            'title': 'Streamflow (m<sup>3</sup>/s)',\n",
    "            'range': [0, 1.2 * plot_data['y_max']]\n",
    "        },\n",
    "        shapes=[\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r2'],\n",
    "                y1=plot_data['r10'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='yellow'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r10'],\n",
    "                y1=plot_data['r20'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='red'\n",
    "            ),\n",
    "            go.layout.Shape(\n",
    "                type='rect',\n",
    "                x0=startdate,\n",
    "                x1=enddate,\n",
    "                y0=plot_data['r20'],\n",
    "                y1=1.2 * plot_data['y_max'],\n",
    "                line={'width': 0},\n",
    "                opacity=.4,\n",
    "                fillcolor='purple'\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    figure = Figure([Scatter(x=plot_data['x_datetime'], y=plot_data['y_flow'])], layout=layout)\n",
    "    if outformat == 'plotly':\n",
    "        return figure\n",
    "    if outformat == 'plotly_html':\n",
    "        return offline_plot(\n",
    "            figure,\n",
    "            config={'autosizable': True, 'responsive': True},\n",
    "            output_type='div',\n",
    "            include_plotlyjs=False\n",
    "        )\n",
    "    return\n",
    "\n",
    "\n",
    "def seasonal_plot(seasonal, reach_id, outformat='plotly'):\n",
    "    if not isinstance(seasonal, pandas.DataFrame):\n",
    "        raise ValueError('Sorry, I only process pandas dataframes right now')\n",
    "    if outformat not in ['json', 'plotly', 'plotly_html']:\n",
    "        raise ValueError('invalid outformat specified. pick json or plotly or plotly_html')\n",
    "\n",
    "    seasonal['day'] = pandas.to_datetime(seasonal['day'] + 1, format='%j')\n",
    "\n",
    "    plot_data = {\n",
    "        'reach_id': reach_id,\n",
    "        'x_day_number': seasonal['day'].tolist(),\n",
    "        'y_flow': seasonal['streamflow_avg (m3/s)'].tolist(),\n",
    "    }\n",
    "\n",
    "    if outformat == 'json':\n",
    "        return plot_data\n",
    "\n",
    "    layout = Layout(\n",
    "        title='Daily Average Streamflow (Historic Simulation)<br>Stream ID: ' + str(reach_id),\n",
    "        xaxis={\n",
    "            'title': 'Date',\n",
    "            'hoverformat': '%b %d (%j)',\n",
    "            'tickformat': '%b'\n",
    "        },\n",
    "        yaxis={\n",
    "            'title': 'Streamflow (m<sup>3</sup>/s)',\n",
    "            'range': [0, 1.2 * max(plot_data['y_flow'])]\n",
    "        },\n",
    "    )\n",
    "    figure = Figure([Scatter(x=plot_data['x_day_number'], y=plot_data['y_flow'])], layout=layout)\n",
    "    if outformat == 'plotly':\n",
    "        return figure\n",
    "    if outformat == 'plotly_html':\n",
    "        return offline_plot(\n",
    "            figure,\n",
    "            config={'autosizable': True, 'responsive': True},\n",
    "            output_type='div',\n",
    "            include_plotlyjs=False\n",
    "        )\n",
    "    return\n",
    "\n",
    "\n",
    "def probabilities_table(stats, ensembles, rperiods):\n",
    "    dates = stats['datetime'].tolist()\n",
    "    startdate = dates[0]\n",
    "    enddate = dates[-1]\n",
    "    start_datetime = datetime.datetime.strptime(startdate, \"%Y-%m-%d %H:00:00\")\n",
    "    span = datetime.datetime.strptime(enddate, \"%Y-%m-%d %H:00:00\") - start_datetime\n",
    "    uniqueday = [start_datetime + datetime.timedelta(days=i) for i in range(span.days + 2)]\n",
    "    # get the return periods for the stream reach\n",
    "    rp2 = rperiods.iloc[3][0]\n",
    "    rp10 = rperiods.iloc[2][0]\n",
    "    rp20 = rperiods.iloc[1][0]\n",
    "\n",
    "    # fill the lists of things used as context in rendering the template\n",
    "    days = []\n",
    "    r2 = []\n",
    "    r10 = []\n",
    "    r20 = []\n",
    "    for i in range(len(uniqueday) - 1):  # (-1) omit the extra day used for reference only\n",
    "        tmp = ensembles.loc[uniqueday[i]:uniqueday[i + 1]]\n",
    "        days.append(uniqueday[i].strftime('%b %d'))\n",
    "        num2 = 0\n",
    "        num10 = 0\n",
    "        num20 = 0\n",
    "        for column in tmp:\n",
    "            if any(i > rp20 for i in tmp[column].to_numpy()):\n",
    "                num2 += 1\n",
    "                num10 += 1\n",
    "                num20 += 1\n",
    "            elif any(i > rp10 for i in tmp[column].to_numpy()):\n",
    "                num10 += 1\n",
    "                num2 += 1\n",
    "            elif any(i > rp2 for i in tmp[column].to_numpy()):\n",
    "                num2 += 1\n",
    "        r2.append(round(num2 * 100 / 52))\n",
    "        r10.append(round(num10 * 100 / 52))\n",
    "        r20.append(round(num20 * 100 / 52))\n",
    "\n",
    "    path = os.path.abspath(os.path.join(os.path.dirname(__file__), 'templates', 'probabilities_table.html'))\n",
    "    with open(path) as template:\n",
    "        return jinja2.Template(template.read()).render(days=days, r2=r2, r10=r10, r20=r20)\n",
    "\n",
    "\n",
    "# AUXILIARY FUNCTIONS\n",
    "def reach_to_region(reach_id):\n",
    "    \"\"\"\n",
    "    returns the delineation region name corresponding to the range of numbers for a given reach_id.\n",
    "    does not validate that the reach_id exists in the region, just associates a number to a name.\n",
    "    \"\"\"\n",
    "    # Indonesia 1M's\n",
    "    # ------australia 2M (currently 200k's)\n",
    "    # Japan 3M's\n",
    "    # East Asia 4M's\n",
    "    # South Asia 5M's\n",
    "    # ------middle_east 6M (currently 600k's)\n",
    "    # Africa 7M's\n",
    "    # Central Asia 8M's\n",
    "    # South America 9M's\n",
    "    # West Asia 10M's\n",
    "    # -------central_america 11M (currently 900k's)\n",
    "    # Europe 12M's\n",
    "    # North America 13M's\n",
    "\n",
    "    lookup = OrderedDict([\n",
    "        # IMPROPERLY NUMBERED REGIONS\n",
    "        ('australia-geoglows', 300000),\n",
    "        ('middle_east-geoglows', 700000),\n",
    "        ('central_america-geoglows', 1000000),\n",
    "        # CORRECTLY NUMBERED REGIONS\n",
    "        ('indonesia-geoglows', 2000000),\n",
    "        ('japan-geoglows', 4000000),\n",
    "        ('east_asia-geoglows', 5000000),\n",
    "        ('south_asia-geoglows', 6000000),\n",
    "        ('africa-geoglows', 8000000),\n",
    "        ('central_asia-geoglows', 9000000),\n",
    "        ('south_america-geoglows', 10000000),\n",
    "        ('west_asia-geoglows', 11000000),\n",
    "        ('europe-geoglows', 13000000),\n",
    "        ('north_america-geoglows', 14000000)\n",
    "    ])\n",
    "    for region, threshold in lookup.items():\n",
    "        if reach_id < threshold:\n",
    "            return region\n",
    "    return None\n",
    "\n",
    "\n",
    "def reach_from_latlon(lat, lon):\n",
    "    \"\"\"\n",
    "    uses the bounding boxes of all the regions to determine which comid_lat_lon_z csv(s) to read from\n",
    "    \"\"\"\n",
    "    # create a shapely point for the querying\n",
    "    point = Point(float(lon), float(lat))\n",
    "    regions_to_check = []\n",
    "    # store the best matching stream using a named tuple for easy comparisons/management\n",
    "    StreamResult = namedtuple('Stream', 'reach_id, region, distance')\n",
    "    stream_result = StreamResult(None, None, math.inf)\n",
    "\n",
    "    # open the bounding boxes csv, figure out which regions the point lies within\n",
    "    bb_csv = pandas.read_csv('delineation_data/bounding_boxes.csv', index_col='region')\n",
    "    for row in bb_csv.iterrows():\n",
    "        bbox = box(row[1][0], row[1][1], row[1][2], row[1][3])\n",
    "        if point.within(bbox):\n",
    "            regions_to_check.append(row[0])\n",
    "\n",
    "    # if there weren't any regions, return that there was an error\n",
    "    if len(regions_to_check) == 0:\n",
    "        return {\"error\": \"This point is not within any of the delineation regions supported.\"}\n",
    "\n",
    "    # check the lat lon against each of the region csv's that we determined were an option\n",
    "    for region in regions_to_check:\n",
    "        # TEMPORARY until we figure out how to fix the west asia problem, skip it\n",
    "        if region == 'west_asia-geoglows':\n",
    "            pass\n",
    "\n",
    "        # open the region csv, find the closest reach_id\n",
    "        df = pandas.read_csv(\n",
    "            f\"delineation_data/{region}/comid_lat_lon_z.csv\", sep=',', header=0, index_col=0)\n",
    "        points_df = df.loc[:, \"Lat\":\"Lon\"].apply(Point, axis=1)\n",
    "        multi_pt = MultiPoint(points_df.tolist())\n",
    "        nearest_pt = nearest_points(point, multi_pt)\n",
    "        reach_id = int(points_df[points_df == nearest_pt[1]].index[0])\n",
    "\n",
    "        # is this a better match than what we have? if so then replace the current selection\n",
    "        distance = nearest_pt[0].distance(nearest_pt[1])\n",
    "        if distance < stream_result.distance:\n",
    "            stream_result = StreamResult(reach_id, region, distance)\n",
    "\n",
    "    # there was only 1 option, return it\n",
    "    if stream_result.distance > 0.11:\n",
    "        return {\"error\": \"Nearest river is more than ~10km away.\"}\n",
    "    else:\n",
    "        return dict(reach_id=stream_result.reach_id, region=stream_result.region, distance=stream_result.distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "provide a reach_id or both a lat and lon value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28600e439fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f1fa658d5ac8>\u001b[0m in \u001b[0;36mforecast_stats\u001b[0;34m(reach_id, lat, lon, api_source, api_key, return_format)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mreach_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreach_from_latlon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reach_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'provide a reach_id or both a lat and lon value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'reach_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreach_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'return_format'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreturn_format\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# build and execute a request to the api with the user's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: provide a reach_id or both a lat and lon value"
     ]
    }
   ],
   "source": [
    "forecast_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'delineation_data/bounding_boxes.csv' does not exist: b'delineation_data/bounding_boxes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8fe6ab962846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mforecast_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f1fa658d5ac8>\u001b[0m in \u001b[0;36mforecast_stats\u001b[0;34m(reach_id, lat, lon, api_source, api_key, return_format)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreach_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mreach_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreach_from_latlon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reach_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'provide a reach_id or both a lat and lon value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f1fa658d5ac8>\u001b[0m in \u001b[0;36mreach_from_latlon\u001b[0;34m(lat, lon)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;31m# open the bounding boxes csv, figure out which regions the point lies within\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0mbb_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delineation_data/bounding_boxes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbb_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geoglows-env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geoglows-env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geoglows-env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geoglows-env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/geoglows-env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'delineation_data/bounding_boxes.csv' does not exist: b'delineation_data/bounding_boxes.csv'"
     ]
    }
   ],
   "source": [
    "forecast_stats(lat=10, lon=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
