{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nGroup Lasso regularization\n==========================\n\nComparison of solvers for problems with a group lasso regularization.\n\nThe group lasso regularization enters the optimization through\nits proximal operator, which is implemented in copt through the\nfunction prox of object :meth:`copt.utils.GroupL1`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copt as cp\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import sparse\n\nnp.random.seed(0)\n\n# .. generate some data ..\nn_samples, n_features = 100, 100\ngroups = [np.arange(10 * i, 10 * i + 10) for i in range(10)]\n\n# .. construct a ground truth vector in which ..\n# .. group 4 and 5 are nonzero ..\nground_truth = np.zeros(n_features)\nground_truth[groups[4]] = 1\nground_truth[groups[5]] = 0.5\n\nmax_iter = 5000\nprint(\"#features\", n_features)\n\nA = sparse.rand(n_samples, n_features, density=0.2)\nsigma = 1.0\nb = A.dot(ground_truth) + sigma * np.random.randn(n_samples)\n\nnp.random.seed(0)\nn_samples = n_features\n\n# .. compute the step-size ..\nf = cp.utils.SquareLoss(A, b)\nstep_size = 1.0 / f.lipschitz\n\n# .. run the solver for different values ..\n# .. of the regularization parameter beta ..\nall_betas = [0, 1e-2, 1e-1, 0.2]\nall_trace_ls, all_trace_nols = [], []\nout_img = []\nfor i, beta in enumerate(all_betas):\n    print(\"beta = %s\" % beta)\n    G1 = cp.utils.GroupL1(beta, groups)\n\n    def loss(x):\n        return f(x) + G1(x)\n\n    cb_tosls = cp.utils.Trace()\n    x0 = np.zeros(n_features)\n    pgd_ls = cp.minimize_proximal_gradient(\n        f.f_grad,\n        x0,\n        G1.prox,\n        step_size=step_size,\n        max_iter=max_iter,\n        tol=1e-14,\n        verbose=1,\n        callback=cb_tosls,\n    )\n    trace_ls = np.array([loss(x) for x in cb_tosls.trace_x])\n    all_trace_ls.append(trace_ls)\n\n    cb_tos = cp.utils.Trace()\n    x0 = np.zeros(n_features)\n    pgd = cp.minimize_proximal_gradient(\n        f.f_grad,\n        x0,\n        G1.prox,\n        step_size=step_size,\n        max_iter=max_iter,\n        tol=1e-14,\n        verbose=1,\n        callback=cb_tos,\n    )\n    trace_nols = np.array([loss(x) for x in cb_tos.trace_x])\n    all_trace_nols.append(trace_nols)\n    out_img.append(pgd.x)\n\n\n# .. plot the results ..\nfig, ax = plt.subplots(2, 4, sharey=False)\nxlim = [0.02, 0.02, 0.1]\nmarkevery = [1000, 1000, 100, 100]\nfor i, beta in enumerate(all_betas):\n    ax[0, i].set_title(r\"$\\lambda=%s$\" % beta)\n    ax[0, i].set_title(r\"$\\lambda=%s$\" % beta)\n    ax[0, i].plot(out_img[i])\n    ax[0, i].plot(ground_truth)\n    ax[0, i].set_ylim((-0.5, 1.5))\n    ax[0, i].set_xticks(())\n    ax[0, i].set_yticks(())\n\n    fmin = min(np.min(all_trace_ls[i]), np.min(all_trace_nols[i]))\n    scale = all_trace_ls[i][0] - fmin\n    plot_tos, = ax[1, i].plot(\n        (all_trace_ls[i] - fmin) / scale, lw=4, marker=\"o\", markevery=100, markersize=10\n    )\n\n    plot_nols, = ax[1, i].plot(\n        (all_trace_nols[i] - fmin) / scale,\n        lw=4,\n        marker=\"h\",\n        markevery=markevery[i],\n        markersize=10,\n    )\n\n    ax[1, i].set_xlabel(\"Iterations\")\n    ax[1, i].set_yscale(\"log\")\n    ax[1, i].set_ylim((1e-14, None))\n    ax[1, i].grid(True)\n\n\nplt.gcf().subplots_adjust(bottom=0.15)\nplt.figlegend(\n    (plot_tos, plot_nols),\n    (\"PGD with line search\", \"PGD without line search\"),\n    ncol=5,\n    scatterpoints=1,\n    loc=(-0.00, -0.0),\n    frameon=False,\n    bbox_to_anchor=[0.05, 0.01],\n)\n\nax[1, 0].set_ylabel(\"Objective minus optimum\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}